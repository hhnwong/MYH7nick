#top: check jobs

#extract mutation from excel
python ExtractExcelMutations.py

#remove duplicates in PD and SNP
sort -u file > newfile

#add accession code to the front of each line
# ^ is the start of a line
sed 's/^/P12883 /' snp.mut

#check there are no entries from both files
awk 'NR==FNR{a[$0];next} ($0 in a)' file1 file2

weka used: 3-8-3
##################################################
HCM/DCM set  with header

PD set without header

SNP without header
###################################################

02/10/19
extracted mutations from all datasets (Luis, DCM_HCM, Axiom) in *.mut 
duplicates removed in *_removed.mut

03/10/19
ran SAAP pipeline for all datasets output: ~/Documents/MYH7nick/*/*_out_date/JSON
converted JSON output files into csv output: ~/Documents/MYH7nick/*/*_out_date/CSV
concatenated all csv into one for each set *final.csv

04/10/19
concatenated three csv files from each set into one
snp_out_031019 wrong data, did not remove common mutations from DCM_HCM set
re-concatenated the data after modification to *final.csv
trained models (train_new) lower MCC than expected (-I (tree) 10 20 50 100 200 300 400) output: ~/Documents/MYH7nick/train_myh7/output/041019

07/10/19
corrected input csv in model training (removed duplicates in PD set from SAAP analysis)
new models (-I (tree) 10 20 50 100 200 300 400) output: ~/Documents/MYH7nick/train_myh7/output/071019_L456_K0_I400 with corrected input data
new models (-I (tree) 50 100 500 1000, -K 20) output: ~/Documents/MYH7nick/train_myh7/output/071019_L456_K20_I1000
new models with lower limit (300) to check if some 'SNPs' are actually SNP (-I (tree) 10 20 50 100 200 300 400) output: ~/Documents/MYH7nick/train_myh7/output/071019_L300_K0_I400
	compare with 071019_L456_K0_I400
	result: all models performing worse than using L456 except for one set, potential that some SNPs are not actually SNP
        future direction: explore number of features
09/10/19
new models (-I (tree) 50 100 500 1000, -K 0/10/15) output: ~/Documents/MYH7nick/train_myh7/output/091019_L456_K(0/10/15)_I1000
	benchmark features number, compare with 071019_L456_K20_I1000
	redo K0/10 I1000 training, no output in some models
	result: using -K 0/10 seems to obtain better results (-K 0 selected 32 features)
	future direction: rank features, engineer features

11/10/19
new models with built in features ranking (based on average impurity decrease, embedded method)

14/10/19
new models with features removed (all MLargest, NLargest, CisPro, SSGeom) Set 1
new models with features removed (6-10 MLargest, NLargest, CisPro, SSGeom) Set 2
new models with features removed (2-10 MLargest, NLargest, CisPro, SSGeom) Set 3
	result: 1 > 3 > 2 in terms of performance (MCC)
	future direction:
			-look at using the delta of the MLargestVoidX NLargestVoidX data rather than the numbers themselves
			-use pretrained predictor for our json files
				write some codes to extract the prediction and compare to see if it is actually PD or SNP, calculate confusion matrix
				use ~martin/scripts/mcc.pl -tp=xxx -fp=xxx -tn=xxx -fn=xxx to calculate MCC
			-clustering mutations, Plot the value from the left hand side of the dendogram against a linear x-axis to look for a sudden jump in values as an indicator of 			     the number of clusters and where an outlying set might be
			-have a look at using Kohonen self-organizing maps and PCA as ways of doing the clustering of the SNPs and looking for outliers

			-try support vector machines, PCA for features selection
			-try oversampling

			-Start to look at adding the other physiological data to the CSV files in order to start looking at sudden cardiac event prediction
			-Look online at methods for dealing with missing data and interpolated learning
				 Talk to Gil as one way of doing this is with auto-encoders
